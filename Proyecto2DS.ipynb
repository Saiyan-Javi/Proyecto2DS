{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cea831",
   "metadata": {},
   "source": [
    "# Proyecto 2\n",
    "## Data Science, sección 40\n",
    "## Grupo 1\n",
    "Javier Alejandro Ovalle Chiquín, 22103  \n",
    "José Ángel Morales Farfan, 22689  \n",
    "Ricardo Josué Morales Contreras, 22289  \n",
    "Karen Daniela Pineda Ventura 231132"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edd5c5",
   "metadata": {},
   "source": [
    "## Planteamiento inicial del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4f247",
   "metadata": {},
   "source": [
    "### Situación problemática\n",
    "Los estudiantes realizan resúmenes en respuesta a una consigna, luego evaluadores puntúan cada resumen en dos factores: content (Si el resumen cubre lo solicitado) y wording (calidad de la redacción). Evaluar manualmente esto es costoso, lento y potencialmente inconsistente. Por lo que, automatizar la evaluación con modelos de PLN puede permitir retroalimentación a escala, detectar rápido resúmenes que necesiten intervención y homogeneizar criterios.\n",
    "\n",
    "### Problema científico\n",
    "Construir modelos de Procesamiento del Lenguaje Natural que, a partir del texto del resumen y del enunciado del prompt, predigan dos puntuaciones continuas (content y wording) de forma que se reduzca la discrepancia con respecto a las evaluaciones realizadas manualmente.\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "Objetivo general\n",
    "\n",
    "- Diseñar, implementar y evaluar un pipeline de PLN que prediga las puntuaciones content y wording de resúmenes estudiantiles con una evaluación cuantitativa reproducible (RMSE, correlaciones).\n",
    "\n",
    "Objetivos específicos\n",
    "\n",
    "- Implementar preprocesamiento reproducible (tokenización, limpieza) y documentar su efecto en la calidad de features\n",
    "\n",
    "- Entrenar un baseline (TF-IDF + Ridge) validado por prompt con GroupKFold y obtener RMSE por target; comparar resultados con una línea base (por ejemplo, promedio)\n",
    "\n",
    "- Realizar EDA que identifique valores faltantes, distribución de scores, outliers y diferencias entre prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec52ae",
   "metadata": {},
   "source": [
    "## Descripción de los datos\n",
    "\n",
    "Variables principales\n",
    "- student_summary: texto escrito por estudiantes\n",
    "- prompt: enunciado al que responde el resumen\n",
    "- content: puntuación otorgada al contenido\n",
    "- wording: puntuación de la redacción\n",
    "\n",
    "Operaciones de limpieza\n",
    "- Conversión a minúsculas\n",
    "- Eliminación de signos de puntuación, caracteres especiales y stopwords\n",
    "- Tokenización y lematización\n",
    "- Manejo de valores faltantes (textos vacíos se reemplazan por cadenas vacías)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da4fb4",
   "metadata": {},
   "source": [
    "## Investigación preliminar\n",
    "\n",
    "**Técnicas comunes para detección de patrones de texto**\n",
    "\n",
    "**El preprocesamiento de Lenguaje Natural (PLN)** busca extraer conocimiento útil a partir de textos. En problemas como el de la competencia, el objetivo es detectar patrones en los resúmenes escritos por estudiantes que permitan estimar automáticamente la calidad de su contenido y redacción.\n",
    "\n",
    "Entre las técnicas están:\n",
    "\n",
    "Preprocesamiento de texto\n",
    "Antes de aplicar cualquier modelo, es necesario transformar el texto original para que sea más manejable:\n",
    "- Normalización: pasar todo a minúsculas, eliminar signos de puntuación, URLs y caracteres especiales. Esto disminuye el ruido y hace más consistentes los datos.\n",
    "- Tokenización: dividir el texto en unidades (tokens), que suelen ser palabras o subpalabras. Ejemplo: \"The boy runs fast\" = [\"the\", \"boy\", \"runs\", \"fast\"].\n",
    "- Stopwords  removal: eliminación de palabras vacías (the, and, is), que no aportan tanta información\n",
    "- Lematización/Stemming: reducir palabras a su forma base (\"running\" = \"run\"). Permite agrupar variaciones morfológicas\n",
    "- Correción de valores faltantes y outliers: textos muy cortos, vacíos o muy alrgos deben analizarse aparte\n",
    "\n",
    "**Representación vectorial del texto**\n",
    "\n",
    "El texto debe representarse numéricamente para que un modelo pueda procesarlo.\n",
    "\n",
    "**Bolsa de palabras (Bag of words):** Cada documento es representado como un vector de frecuencias de palabras, ignorando el orden. Es simple y útil para detectar patrones de vocabulario físico.\n",
    "\n",
    "**TF-IDF (Term Frecuency - Inverse Document Frecuency):**\n",
    "Pondera palabras según su frecuencia en un documento, penaliza las que son muy frecuentes, lo cual permite detectar palabras clave más relevantes para diferenciar textos.\n",
    "\n",
    "**N-gramas:** Considera secuencias de palabras (bigramas, trigramas). Esto captura patrones de estilo y frases típicas de resúmenes.\n",
    "\n",
    "**Embeddings semánticos:**\n",
    "- Word2Vec, Glove, FastText, representan palabras en vectores densos que capturan similitud semántica (\"dog\" y \"puppy\").\n",
    "- Embeddings contextuales (Transformers como BERT, RoBERTa, DistilBERT) capturan el significado de cada palabra en función de su contexto, lo que permite representar mejor la semántica de frases completas.\n",
    "\n",
    "Patrones estilísticos y estructurales\n",
    "Se pueden usar métricas como:\n",
    "- Longitud del texto: cantidad de caracteres o palabras\n",
    "- Riqueza léxica: proporción de palabras únicas frente al total\n",
    "- Medidas de legibilidad: índices como Flesh-Kincaid, que miden la complejidad sintáctica\n",
    "- Distribución de puntuación y longitud de oraciones: redacción más clara suele usar estructuras más balanceadas\n",
    "\n",
    "**Modelos para detección de patrones**\n",
    "\n",
    "Regresión lineal y Ridge/Lasso: adecuados como modelos base para datos vectorizados (TF-IDF).\n",
    "\n",
    "Árboles de decisión y ensambles (Random Forest, XGBoost, LightGBM): capturan patrones no lineales en los features.\n",
    "\n",
    "Redes neuronales: CNN y RNN, detectan secuencias recurrentes en textos.\n",
    "\n",
    "Transformers (BERT, RoBERTa, GPT, etc): de última generación, capaces de capturar relaciones complejas y contexto profundo, especialmente efectivos evaluación de calidad de texto.\n",
    "\n",
    "**Evaluación de patrones**\n",
    "\n",
    "Métricas cuantitativas: RMSE (Root Mean Squared Error), MAE (Mean Absolute Error) y correlaciones estadísticas.\n",
    "\n",
    "Validación cruzada estratificada por prompt: asegura que el modelo no se sobreajuste, ya que los resúmenes son de temas distintos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e70d48",
   "metadata": {},
   "source": [
    "Ahora cargaremos las librerías necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3342b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.model_selection import check_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3aa073",
   "metadata": {},
   "source": [
    "Para la configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00bcd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Javier\n",
      "[nltk_data]     Chiquin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Javier\n",
      "[nltk_data]     Chiquin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Javier\n",
      "[nltk_data]     Chiquin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Visual config\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "# Inicializar NLTK\n",
    "for resource in ['punkt', 'punkt_tab', 'stopwords']:\n",
    "    try:\n",
    "        nltk.data.find(resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource)\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Directorio de datos\n",
    "DATA_DIR = Path('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
